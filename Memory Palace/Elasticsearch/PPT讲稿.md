

# 目录

各位同事好

我是北京大数据平台部的刘明

今天，我给大家做一个关于Elasticsearch基本原理的介绍。

和大家一起讨论一下ES的一些基本概念和相关的原理。

=======================翻=====================

# 框架

我们这次主要围绕六个方面来介绍ES的基本概念，分别是：





目的是可以让大家在以后的开发生产和使用中，对ES有一个相对较为整体的了解。

=======================翻=====================



# 定义

学习一个东西

首先要给它一个明确的定义



Elasticsearch是什么？



相信大多初学ES的同学，都多多少少觉得ES就是一个分布式数据库，比mysql，oracle能储存的数据量大一些，查询快一点。

但实际上，我们跑到ES的官网看一下。官方给了我们一个明确的定义。



严格意义来讲，它并不是一个数据库。它是一个搜索和数据分析引擎。

搜索引擎和数据库都是用来查数据的，但是他们之间是有明显区别的。

=======================翻=====================

什么是搜索引擎呢，就是我们平常使用的谷歌、百度、必应之类的查询信息的工具。通过我们提供的搜索关键词，找出相关的网页。

=======================翻=====================

那么搜索引擎和数据库到底有什么不同呢？

搜索引擎搜索的是**非结构化数据**

查询前无需知道数据在哪个索引，哪个分片，甚至哪个字段

本身会对**查询条件**进行延伸，比如分词、近义词、联想词

数据库查询的是结**构化数据**

编写查询条件的时候，就必须提前知道数据结构

本身也不会对查询条件做任何延伸，所得即所查。



今天我们要介绍的Elasticsearch就是一款开源的数据搜索引擎

=======================翻=====================

我们通常所说的和Elasticsearch相关的ELK Stack, 是以ES为中心，Elastic公司建立的一整套企业级的搜索解决方案

我们只要把ES学懂了，其他组件可以根据需要去学习，而且掌握了ES后，学习起其它组件的使用方法就相对简单了。因为所有其他ELK stack中的组件都是围绕着ES来构建的。



接着我们来讲一下

# ES的部署和安装

=======================翻=====================

ES提供了几乎针对所有系统的安装包，yum、tar.gz、msi等。安装完成后，会包含如下目录：

具体的安装步骤可以根据文档一步步来进行，我们就不演示了。关于安装步骤，我简单翻译了一下，提取了一些步骤，有需要的同学下来也可以管我要文档。





那我们进入下一节，ES中的一些基本的概念。

# 基本概念

=======================翻=====================

ES查词查得快，主要靠**倒排索引**。那么在介绍倒排索引之前？我们先来看下什么是**正排索引**

正排索引就是我们通常看一本书的目录，包含了哪一章节在哪一页

如果我们把这本书按照正排索引存储起来，比如放到mysql中

=======================翻=====================

用Mysql就会形成如下的表结构，如果我们想查询哪篇文章中包含 programing关键字，

就得用下面的查询语句

mysql就会解析这个语句，到content字段中去将所有内容正则匹配一遍。

我们都知道正则匹配一般实现都是AC自动机，再怎么优化，时间复杂度都不会小于内容的长度，如果文档数量太大，或者每篇文章的内容比较长，那么时间复杂度就会非常高，耗时会相当长。



这时候，针对这个查询关键字的需求，就需要用到 **倒排索引**了

那么什么是倒排索引呢，我们怎么利用倒排索引去提高查询关键词的效率呢

=======================翻=====================

最简单的倒排索引，就像我们读的一些技术类书籍的末尾，会给出一个像关键词索引的章节。

里面的关键词按字母序排列，关键词出现的页码在相应的关键词后面被标出。



用表来展示，就像这样

=======================翻=====================

正排索引存储文档，会像这样，一个字段存储文档ID，一个字段存储文档内容。

倒排索引呢，就会把文档内容全部分词，提取其中的关键词，记录每个关键词出现的次数，以及出现在哪些文档中，以及相应的位置。

那么再返回到刚才的需求，我们要查一个关键词就很容易了，只需要O（1）的复杂度就能查出哪篇文章包含相应的关键词了。

=======================翻=====================

那么ES中的倒排索引是什么样的呢？

ES中的倒排索引包含两部分，一部分是单词词典，记录所有的term关键词到倒排列表的关系，一般是用B+树或者哈希拉链表实现的。

通过单词词典找到相应的倒排列表之后，就能够根据倒排列表找到term相关的文档ID, 词频、文档中的位置、偏移量。

=======================翻=====================



那么就有同学肯定要问了，ES除了保存全文数据之外，还有其他数据类型，比如int、date、ip、经纬度之类的。那这些数据查询也很快，也是通过倒排索引实现的么？

我们也发现了，如果用哈希表实现倒排索引的化，没法用range的方式来聚合数据啊。数据分布都是随机的。那ES是怎么存储其他格式的数据的呢？

答案就是BKD树，它和BST树很像，在BST树的基础之上引入了一个K作为维度转换的因数。

有兴趣的同学可以下去研究一下。ES这里实现多维数据的查询十分巧妙。

=======================翻=====================

好的，我们接着往下讲，

通常我们关注ES的主要分两种人员，一种是我们的开发人员或者使用人员，我们主要关心这个数据怎么查出来，怎么保存的。另一种是我们的运维人员，主要关心的是ES作为一个分布式框架，是如何组织服务的。

=======================翻=====================

首先，我们讲下

ES中是如何组织数据模型的呢。总共分为三级结构，当然7.0以后可以算作两级结构。

=======================翻=====================

一个文档又包含哪写元数据信息呢

要注意的是_score不是默认存储的，是结合查询语句算出来的，后面会介绍ES的算分机制。



那么我们从开发人员或者使用人员的角度讲完了ES的数据模型，下面讲下运维人员比较关心的ES集群的构成



=======================翻=====================

我们通常将ES集群由大到小分为三个不同的**工作单元**，一是整个集群，二是node节点，三是shard分片。

首先我们讲一下集群

ES作为一个分布式集群，它满足

高可用性、

部分节点丢失，不会停止服务，不会丢失数据。

可扩展

随着请求量的提升、数据的不断增长，可以将数据分布到所有节点上

不同的集群，是以集群名称来区分的。比如我们有些混部的系统，可能ip相同但是端口不同。节点如何确定加入了正确的集群，客户端如何确定查询的是正确的集群。我们就要通过clusterName来区分。

通常我们在运维过程中，最直观的就是观察集群的状态

集群状态分三类

这里要说下的是，虽然red了，不代表集群就完全不能用。有些green状态的索引还是可以正常查询的。可能只是某些索引的主分片未能正常分配，就会使整个集群报red状态。



Cluster集群是由一个个节点组成的

=======================翻=====================

每个节点本质上是一个单独的Java进程



最后就是每个节点下存储的Shard分片

=======================翻=====================

Shard分片分为两类



增加太多的副本分片，并不会让搜索提速，后面我们讲到搜索原理的时候，就会明白其中的原因了



接下来我们讲ES的一些分布式特性

# 分布式特性

=======================翻=====================

既然是分布式集群，根据节点的组织形式，可以分为两大类

一类是ceph、cassandra这样的无主结构，每个节点都是平等的，数据通过哈希算法来存储查询。

另一类就是主从结构，比如ES、hadoop这样的。一个或一群节点专门负责管理集群。ES就是这样的主从架构。

主从架构启动的第一件事就是从已知的活跃机器列表中选择一个作为**主节点**， 选主之后的流程由**主节点**触发。



ES的选主时的算法，主要基于**Bully**算法的改进。主要思路是对节点ID排序，取ID值最大的节点作为Master。简单来说，在bully算法中，每个节点都有一个编号，只有编号最大的存活节点才能成为Master节点



Bully算法有哪写缺陷呢

=======================翻=====================

一个就是Master 假死的问题





来回切换主节点，会使整个集群状态就会非常不可靠。



Elasticsearch是如何解决这个问题的呢？

ES中的某个节点在延迟得到主节点反馈的情况下，会先像集群内的其它节点去发起询问，是不是要进行选举。如果超过1/2以上的节点都确认主节点失效了，才会去发动选举。这样主节点可能过一会儿和该节点的通信恢复了，避免了来回频繁的切换主节点。



另一个bully算法的问题是，脑裂问题。

=======================翻=====================

当然这个问题只要配置好了，我们很少能碰到。这个问题时什么呢，当一个集群因为网络问题，选出了两个主节点。这样就变成两个集群了。当网络恢复的时候，就无法正确恢复集群了。

ES是如何解决这个问题的呢？

ES在配置中引入了一个多数仲裁的机制，比如有三个master eligible节点，我们设置这个参数为2，假设主节点挂了，只有在master eligible大于2的时候才会触发选主流程，也就是说当前所有节点还在一个集群中互相通信，但是 没有主。只有当新加入一个master eligible节点，或者原来的master节点恢复了，才会触发选主流程。这样就不会分裂成两个集群了。



讲完了选主流程，我们讲一下ES中的doc文档是如何分配到各个机器上的

=======================翻=====================

一般分布式框架有几种策略，轮询，哈希，指定ID。ES采取的就是哈希加指定ID的模式。具体公式是这样的。



当然也可以指定routing，这样会增加查询算分的准确性，查询该网站数据的时候速度也会提升。



注意看最后一个参数，主分片数量。文档怎么分配是和主分片的数量相关的，所以一开始创建索引的时候设定好了主分片数，就不能随意修改了。因为要是改了的话，要重新分配所有数据到正确的节点上，这是一个很重的操作。



=======================翻=====================

文档在shard中是如何保存的呢？

前面我们讲了，一个shard就是一个lucene index。

文档写入lucene的时候要分词，被存储到segment中

写入新文档，会生成新的segment。

删除文档的时候，会先保留在.del文件中。查询的时候会根据.del进行过滤。

这也是就为什么说ES中的doc删除不是真正的删除，ES可以进行数据变更，但是变更多了会对搜索效率有很大的影响。



那么从ES收到写入文档的请求，到真正的存储落地时经历了一个怎样的流程呢？

=======================翻=====================

* 在写数据的时候，先会将数据写入Index Buffer（内存）。一定频率（index.refres_interval）写入segment文件中去。将Index Buffer写入Segment（os cache）的过程叫**Refresh**。Refresh不执行fsync操作。
*  index.refres_interval默认是1秒。Refresh之后就可以被搜索到了。这就是ES被称作近实时搜索的原因
*  如果系统有大量数据写入，就会产生很多Segment
*  Index Buffer 被占满时也会触发Refresh，默认是JVM堆内存的10%



Segment写入磁盘的过程相对耗时，借助os cache，refresh时先将Segment写入缓存以开放查询

=======================翻=====================



* 为了保证数据不丢失。所以在做doc索引时，同时写入Transaction Log。
* Transaction log就相当于索引的变更日志。就类似于关系型数据库中的change log
* Transaction Log默认每隔5s或者在一个变更请求之后刷入磁盘。可以通过减小Transaction Log的刷盘频率来保障数据的可靠性，但是性能影响较大。
* 在ES Refresh时，Index Buffer被清空，Transaction Log不会清空。



数据也不能一直放内存里，接下来就是flush

=======================翻=====================

ES的flush

一个完整的flush流程

  * 调用Refresh， Index Buffer清空并且Refresh

  * 调用系统的file sync，将系统缓存中的Segments写入磁盘

  * lucene 更新commit point

  * 清空（删除）Transaction Log

    默认调用

  * 默认30分钟调用一次

  * Transaction Log满了会调用一次（默认512 MB）



=======================翻=====================

最后一步就是segments文件的整理，像接收大量请求的时候，会生成很多的segments。

发生变更的时候，也会产生.del文件

小文件的存储会占用大量系统句柄。所以ES就使用merge操作来处理文档存储中产生的小文件。

一个merge操作会：





讲完了存储，我们来讲一下ES的查询原理

=======================翻=====================

ES中的查询，一般都分为两个阶段

一是query，接收到请求的coordinating节点，会在shard的in-sync列表中随机选择。

这里说下，不是全部主副分片都会去查询，而是在编号相同的分片中随机选择一个。并且副本分片是要在集群的in-sync列表中的。

随机选择shard之后，会在被选中的分片中执行查询，排序。返回From + Size个排序后的文档ID和排序值给Coordinating节点。



接下来是第二部，fetch

coordinating节点会将第一阶段的doc id列表，重新排序，最后选取From + Size个文档ID，用multi get的方式，到相应的分片获取详细的文档数据。

当然这种二阶段查询会产生一些潜在问题：

=======================翻=====================

每个分片上要取from + size个文档，比如50个分片，from + size = 10000。 最后要coordinate节点要排序处理的数据就是50W。 from + size越增大，coordinate节点的处理压力是成倍递增的。这就是为什么ES不支持深度翻页。因为它存储的时候就不是按照关系型数据库那样，有一个递增的ID值，单调递增存储的。



另一个问题就是相关性算分不准的问题。

* 解决相关性算分不准的方式 * 数据量不大时，将主分片数设置为1 
* _search?search_type=dfs_query_then_fetch  
* 等同于到每个分片把各分片的词频和文档频率进行搜集，然后进行一次完整的相关性算分。耗费更多的CPU和内存，执行效率低下，一般不建议使用。



说到搜索的相关性算分，我们这里就讲一下ES相关性算分的基本原理

=======================翻=====================

这就是我们之前提到的文档的元数据中的_score



我们思考一下，什么情况下，一个文档符合了哪些条件，它更可能是你想搜索的文档呢？

ES里面就给了两个比较重要的因子，

一是词频， 比如你查询 elasticsearch，elasticsearch在文章a中出现了100次，但是在文章b中只出现了1次。那是不是文章a肯定就是你更想要查到的文章。



二是 文档中出现的频率。 解释一下就是，你有10亿篇文档，你想查‘区块链的应用’，分词算法把查询条件分为

‘区块链’、

‘应用’ 和 ‘的’ 这三个词

区块链在10亿篇中的200万个文档里出现过，的 10 亿篇出现过，应用 在5亿篇出现过

那么哪个词对你搜索的相关性贡献大呢？

肯定是区块链。

那么我们如何表示它对我们的相关性贡献大呢，那么就是对数了。

IDF，逆文档频率，它所要表示的就是查询语句中的哪个词对我们的搜索相关性贡献更大



ES 中的相关性算分公式是这样的：

=======================翻=====================



boosting参数可以做一个手动的提升。

通过这个公式，ES就给出了一个文档根据查询语句的相关性算分。

ES中可以通过explain参数查看算分过程



说完搜索，那么说一说ES的另一个特性，聚合

=======================翻=====================

聚合是什么呢？

我们平时搜索旅游网站的时候，查一个酒店，旁边都会给出一个过滤条件

价格范围

每个价格范围后面都跟了个数字，表示这个价格范围内的酒店有多少家。

那么这个数字是怎么得来的呢，就是通过搜索引擎的聚合功能。

=======================翻=====================

ES目前支持这几类聚合操作

比较常用的就是Bucket和Metric



最后我们讲一下ES集群的扩展和运维

# 集群扩展和运维

=======================翻=====================

下面这幅图是最基本的ES部署场景

优势就是data和coordinating节点可以随时拓展



通常理想的情况下，我们尽量建议每个服务器都只部署一个ES节点，，每个ES节点只承担**单一职责**

master节点就负责管理更新集群状态

data节点就负责存储和查询数据

coordinating就负责接收请求，计算汇聚查询结果



如果非要混部的情况，建议把master节点和data节点混部，至少也要把coordinating节点单独分离出去。

  * data node相对占用内存较大
  * coordinating node有时开销比较高，导致OOM
      * 影响到master节点会导致集群不稳定



=======================翻=====================

为了避免请求都打到一个coordinating节点上，我们还可以在coordinating节点之前加上一个负载均衡（load balance）

=======================翻=====================

如果我们部署的时候，data节点有多种机器配置，那么就可以根据数据和机器配置的特性，来搭建一套Hot & warm架构。

热数据使用高性能的SSD盘，提高IO效率。

冷数据定期转移到warm节点，甚至close掉来节约内存。



=======================翻=====================

通常ES在启动的时候，会对系统环境进行一个引导检查，启动过程必须通过这个bootstrap check，否则就会启动失败。

bootstrap check可以分为两类



我们测试的一个比较合适的经验值是32000M，这样就可以既保证了指针压缩，又保证了计算内存的最大化



等集群正常启动后，我们在平时的运维工作中，可以定期去采集一些ES中的集群数据，来监测集群的运行

=======================翻=====================

ES提供了一系列的API，来返回集群的状态

有统计信息的stat的相关API



=======================翻=====================

有task和线程池相关的API

=======================翻=====================

还有health相关的API

=======================翻=====================

网上有很多开源的ES监控组件，比如Cerebro之类的，基本都是基于上面的API获取的参数来做的可视化。

所以如果没时间研究这些组件，尽量运维的时候还是去学习一下前面的API。



=======================翻=====================

好了，今天的介绍就到这里。蟹蟹大家。



=======================翻=====================









